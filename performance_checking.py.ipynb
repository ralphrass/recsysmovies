{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# necessary modules\n",
    "import sqlite3\n",
    "import utils\n",
    "import recommender_classifier\n",
    "import evaluation\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from multiprocessing import Process, Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# load random users and feature vectors\n",
    "conn = sqlite3.connect('database.db')\n",
    "Users = utils.selectRandomUsers(conn)\n",
    "\n",
    "LOW_LEVEL_FEATURES, DEEP_FEATURES, HYBRID_FEATURES = utils.extract_features()\n",
    "\n",
    "print len(Users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_user_profile_svm_regressor(conn, user_datasets, feature_vector):\n",
    "    \n",
    "    user_profiles = {}\n",
    "    sum_mae = 0\n",
    "\n",
    "    for user, datasets in user_datasets.iteritems():     \n",
    "        \n",
    "        userInstances, userValues = utils.getUserInstances(datasets['train'], feature_vector)\n",
    "        \n",
    "        clf = svm.SVR(kernel='rbf')\n",
    "        clf.fit(userInstances, userValues)\n",
    "        \n",
    "        user_profiles[user] = {'model': clf.predict, 'datasets': datasets}\n",
    "        # userInstances, userValues = utils.getUserInstances(full_test_set, LOW_LEVEL_FEATURES)\n",
    "\n",
    "        # check the model quality using user's full test set (ratings not used for the model)\n",
    "        # predictions = [(movie[2], clf.predict([feature_vector[movie[0]]])) for movie in full_test_set]\n",
    "        # print predictions\n",
    "        \n",
    "        real_ratings = [x[1] for x in datasets['test']]\n",
    "        predicted_ratings = [clf.predict([feature_vector[movie[0]]]) for movie in datasets['test']]\n",
    "        \n",
    "        # sum_mae += evaluation.evaluateMAE(conn, user, predictions, 0, 1)\n",
    "        sum_mae += mean_absolute_error(real_ratings, predicted_ratings)\n",
    "\n",
    "    mae = utils.evaluateAverage(sum_mae, len(user_datasets))\n",
    "    return user_profiles, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run(user_profiles, N, featureVector):\n",
    "\n",
    "    conn = sqlite3.connect('database.db')\n",
    "    \n",
    "    SumRecall, SumPrecision = 0, 0\n",
    "    \n",
    "    for user, profile in user_profiles.iteritems():                \n",
    "        hits = 0\n",
    "        randomMovies = profile['datasets']['random']\n",
    "        allMovies = profile['datasets']['all_movies']\n",
    "        userBaseline = utils.getUserBaseline(conn, user)\n",
    "        \n",
    "        for eliteMovie in profile['datasets']['elite_test']:\n",
    "\n",
    "            if eliteMovie[0] not in featureVector:\n",
    "                print \"Movie\", eliteMovie[0], \"not in feature vector\"\n",
    "                continue\n",
    "                \n",
    "            # Predict to the user movie and to random movies that the user did not rated\n",
    "            # predictions = recommender_classifier.get_predict(eliteMovie, randomMovies, profile['model'], featureVector)            \n",
    "            predictions = recommender_classifier.get_predict_collaborative_filtering(conn, eliteMovie, randomMovies, allMovies, userBaseline, featureVector)\n",
    "            # print predictions            \n",
    "            hits += recommender_classifier.count_hit(predictions, eliteMovie, N)\n",
    "        try:\n",
    "            recall = hits / float(len(profile['datasets']['elite_test']))\n",
    "            SumRecall += recall\n",
    "            SumPrecision += (recall / float(N))\n",
    "        except ZeroDivisionError:\n",
    "            continue\n",
    "        # print \"Size is\", len(predictions)\n",
    "        # print \"Predictions\", sorted(predictions, key=lambda tup: tup[2], reverse=True)\n",
    "\n",
    "    size = len(user_profiles)\n",
    "    avgRecall = utils.evaluateAverage(SumRecall, size)\n",
    "    avgPrecision = utils.evaluateAverage(SumPrecision, size)\n",
    "\n",
    "    return avgPrecision, avgRecall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split users ratings into training, test and elite test (only high ratings) datasets\n",
    "user_datasets = {}\n",
    "\n",
    "for user in Users:\n",
    "#     print \"User\", user\n",
    "    \n",
    "    userMoviesTraining, userMoviesTest, full_test_set, all_movies = utils.getUserTrainingTestMovies(conn, user[0])\n",
    "    \n",
    "    if len(userMoviesTest) == 0:\n",
    "        continue\n",
    "    \n",
    "    random_movies = utils.getRandomMovieSet(conn, user[0])\n",
    "        \n",
    "    user_datasets[user[0]] = {'all_movies': all_movies, 'train': userMoviesTraining, 'elite_test': userMoviesTest, 'test': full_test_set, 'random': random_movies}\n",
    "\n",
    "# print \"Test Dataset\", user_datasets[user[0]]['test'], len(user_datasets[user[0]]['test']), \"\\n\\n\"\n",
    "# print \"Elite Test Dataset\", user_datasets[user[0]]['elite_test'], len(user_datasets[user[0]]['elite_test']), \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-Level Features MAE 0.789492056203\n",
      "Deep Features MAE 0.795905751459\n"
     ]
    }
   ],
   "source": [
    "# LOW LEVEL FEATURES preprocess users profiles - Support Vector Machine Regressor\n",
    "user_profiles_low_level, mae = train_user_profile_svm_regressor(conn, user_datasets, LOW_LEVEL_FEATURES)\n",
    "print \"Low-Level Features MAE\", mae\n",
    "\n",
    "# DEEP FEATURES preprocess users profiles - SVM\n",
    "user_profiles_deep, mae = train_user_profile_svm_regressor(conn, user_datasets, DEEP_FEATURES)\n",
    "print \"Deep Features MAE\", mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def experiment(N, user_profiles_low_level, LOW_LEVEL_FEATURES, user_profiles_deep, DEEP_FEATURES):\n",
    "            \n",
    "    result = {}\n",
    "\n",
    "    # LOW LEVEL FEATURES check precision, recall and mae\n",
    "    p_l, r_l = run(user_profiles_low_level, N, LOW_LEVEL_FEATURES)\n",
    "    print \"Low-Level Recall\", r_l, \"Low-Level Precision\", p_l, \"For iteration with\", N, \"\\n\\n\\n\"\n",
    "    result[N] = {'ll': {'recall': r_l, 'precision': p_l}}\n",
    "\n",
    "    # DEEP FEATURES check precision, recall and mae\n",
    "    p_d, r_d = run(user_profiles_deep, N, DEEP_FEATURES)\n",
    "    print \"Deep Recall\", r_d, \"Deep Precision\", p_d, \"For iteration with\", N, \"\\n\\n\\n\"\n",
    "    result[N] = {'deep': {'recall': r_d, 'precision': p_d}}\n",
    "\n",
    "    p, r, mae = recommender_classifier.recommend_random(user_datasets, N)\n",
    "    print \"Random Recall\", r, \"Random Precision\",  p, \"Random MAE\", mae, \"For iteration with\", N\n",
    "    result = {'ll': {'recall': r_l, 'precision': p_l}, 'deep': {'recall': r_d, 'precision': p_d}, 'random': {'recall': r, 'precision': p}}\n",
    "   \n",
    "    # FILE_NAME = time.strftime('%d-%m-%Y')+'-imageNet-LSTM-128.txt'\n",
    "\n",
    "#     with open(FILE_NAME, 'a') as resfile:\n",
    "#         resfile.write(result)\n",
    "        \n",
    "    # q.put({N: result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-Level Recall 0.257617845118 Low-Level Precision 0.257617845118 For iteration with 1 \n",
      "\n",
      "\n",
      "\n",
      "Deep Recall 0.230260942761 Deep Precision 0.230260942761 For iteration with 1 \n",
      "\n",
      "\n",
      "\n",
      "Random Recall 0.0340067340067 Random Precision 0.0340067340067 Random MAE 1.7957376136 For iteration with 1\n",
      "1333.87518787\n"
     ]
    }
   ],
   "source": [
    "q = Queue()\n",
    "N = 1\n",
    "start = time.time()\n",
    "procs = [Process(target=experiment, args=(N, user_profiles_low_level, LOW_LEVEL_FEATURES, user_profiles_deep, DEEP_FEATURES,)) for i in range(1)]\n",
    "for p in procs: p.start()\n",
    "for p in procs: p.join()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "#     p = Process(target=experiment, args=(q, N, user_profiles_low_level, LOW_LEVEL_FEATURES, user_profiles_deep, DEEP_FEATURES, Users,))\n",
    "#     p.start()\n",
    "#     N += 1\n",
    "# print q.get()\n",
    "# p.join()\n",
    "\n",
    "# p = Pool(5)\n",
    "# print(p.map(run, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
