{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split users ratings into training, test and elite test (only high ratings) datasets\n",
    "# user_datasets = {}\n",
    "\n",
    "# for user in Users:\n",
    "   \n",
    "#     userMoviesTraining, userMoviesTest, full_test_set, all_movies = utils.getUserTrainingTestMovies(conn, user[0])\n",
    "        \n",
    "#     if len(userMoviesTest) == 0:\n",
    "#         continue\n",
    "    \n",
    "#     random_movies = utils.getRandomMovieSet(conn, user[0])        \n",
    "#     user_datasets[user[0]] = {'all_movies': all_movies, 'train': userMoviesTraining, 'elite_test': userMoviesTest, 'test': full_test_set, 'random': random_movies}\n",
    "\n",
    "# print \"Test Dataset\", user_datasets[user[0]]['test'], len(user_datasets[user[0]]['test']), \"\\n\\n\"\n",
    "# print \"Elite Test Dataset\", user_datasets[user[0]]['elite_test'], len(user_datasets[user[0]]['elite_test']), \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LOW LEVEL FEATURES preprocess users profiles - Support Vector Machine Regressor\n",
    "# user_profiles_low_level, mae = train_user_profile_svm_regressor(conn, user_datasets, LOW_LEVEL_FEATURES)\n",
    "# print \"Low-Level Features MAE\", mae\n",
    "\n",
    "# # DEEP FEATURES preprocess users profiles - SVM\n",
    "# user_profiles_deep, mae = train_user_profile_svm_regressor(conn, user_datasets, DEEP_FEATURES)\n",
    "# print \"Deep Features MAE\", mae\n",
    "\n",
    "# user_profiles = recommender_classifier.build_user_profiles(conn, Users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_user_profile_svm_regressor(conn, user_datasets, feature_vector):\n",
    "    \n",
    "    user_profiles = {}\n",
    "    sum_mae = 0\n",
    "\n",
    "    for user, datasets in user_datasets.iteritems():     \n",
    "        \n",
    "        userInstances, userValues = utils.getUserInstances(datasets['train'], feature_vector)\n",
    "        userBaseline = utils.getUserBaseline(conn, user)\n",
    "        \n",
    "        clf = svm.SVR(kernel='rbf')\n",
    "        clf.fit(userInstances, userValues)\n",
    "        \n",
    "        user_profiles[user] = {'model': clf.predict, 'datasets': datasets, 'baseline': userBaseline}\n",
    "        # userInstances, userValues = utils.getUserInstances(full_test_set, LOW_LEVEL_FEATURES)\n",
    "\n",
    "        # check the model quality using user's full test set (ratings not used for the model)\n",
    "        # predictions = [(movie[2], clf.predict([feature_vector[movie[0]]])) for movie in full_test_set]\n",
    "        # print predictions\n",
    "        \n",
    "        real_ratings = [x[1] for x in datasets['test']]\n",
    "        predicted_ratings = [clf.predict([feature_vector[movie[0]]]) for movie in datasets['test']]\n",
    "        \n",
    "        # sum_mae += evaluation.evaluateMAE(conn, user, predictions, 0, 1)\n",
    "        sum_mae += mean_absolute_error(real_ratings, predicted_ratings)\n",
    "\n",
    "    mae = utils.evaluateAverage(sum_mae, len(user_datasets))\n",
    "    return user_profiles, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# necessary modules\n",
    "import sqlite3\n",
    "import utils\n",
    "import recommender_classifier\n",
    "import evaluation\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from multiprocessing import Process, Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "# load random users and feature vectors\n",
    "conn = sqlite3.connect('database.db')\n",
    "Users = utils.selectRandomUsers(conn)\n",
    "LOW_LEVEL_FEATURES, DEEP_FEATURES, HYBRID_FEATURES = utils.extract_features()\n",
    "\n",
    "print len(Users)\n",
    "\n",
    "user_profiles = recommender_classifier.build_user_profiles(conn, Users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run(user_profiles, N, feature_vector):\n",
    "\n",
    "    conn = sqlite3.connect('database.db')\n",
    "    \n",
    "    SumRecall, SumPrecision = 0, 0\n",
    "    \n",
    "    for user, profile in user_profiles.iteritems():                \n",
    "        \n",
    "        hits = 0\n",
    "        \n",
    "        predictions = recommender_classifier.get_predict_collaborative_filtering(conn, profile, feature_vector)\n",
    "        # print \"Predictions\", sorted(predictions, key=lambda tup: tup[2], reverse=True)\n",
    "        \n",
    "        for elite_movie in profile['datasets']['elite_test']:\n",
    "                        \n",
    "            if feature_vector is list and elite_movie[0] not in feature_vector:\n",
    "                continue\n",
    "                \n",
    "            # Predict to the user movie and to random movies that the user did not rated\n",
    "            # print predictions            \n",
    "            elite_prediction = recommender_classifier.get_prediction_elite(conn, elite_movie, profile, feature_vector)\n",
    "            all_predictions = predictions[:]\n",
    "            all_predictions.append(elite_prediction)\n",
    "            \n",
    "            # print \"Elite Movie\", elite_movie, elite_prediction\n",
    "            \n",
    "            hits += recommender_classifier.count_hit(all_predictions, elite_movie, N)\n",
    "        try:\n",
    "            recall = hits / float(len(profile['datasets']['elite_test']))\n",
    "            SumRecall += recall\n",
    "            SumPrecision += (recall / float(N))\n",
    "        except ZeroDivisionError:\n",
    "            continue\n",
    "        # print \"Size is\", len(predictions)\n",
    "        # print \"Predictions\", sorted(predictions, key=lambda tup: tup[2], reverse=True)\n",
    "\n",
    "    size = len(user_profiles)\n",
    "    avgRecall = utils.evaluateAverage(SumRecall, size)\n",
    "    avgPrecision = utils.evaluateAverage(SumPrecision, size)\n",
    "\n",
    "    return avgPrecision, avgRecall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def experiment(N, user_profiles_low_level, LOW_LEVEL_FEATURES, user_profiles_deep, DEEP_FEATURES):\n",
    "def experiment(N):\n",
    "    \n",
    "    global user_profiles, LOW_LEVEL_FEATURES, DEEP_FEATURES, HYBRID_FEATURES\n",
    "            \n",
    "    result = {}\n",
    "\n",
    "    # COLLABORATIVE FILTERING\n",
    "#     p_c, r_c = run(user_profiles, N, None)\n",
    "#     print \"CF Recall\", r_c, \"CF Precision\", p_c, \"For iteration with\", N, \"\\n\\n\"\n",
    "#     result[N] = {'cf': {'recall': r_c, 'precision': p_c}}\n",
    "    \n",
    "    # LOW LEVEL FEATURES check precision, recall and mae\n",
    "    p_l, r_l = run(user_profiles, N, LOW_LEVEL_FEATURES)\n",
    "    print \"Low-Level Recall\", r_l, \"Low-Level Precision\", p_l, \"For iteration with\", N, \"\\n\\n\"\n",
    "#     result[N] = {'ll': {'recall': r_l, 'precision': p_l}}\n",
    "\n",
    "    # DEEP FEATURES check precision, recall and mae\n",
    "    p_d, r_d = run(user_profiles, N, DEEP_FEATURES)\n",
    "    print \"Deep Recall\", r_d, \"Deep Precision\", p_d, \"For iteration with\", N, \"\\n\\n\"\n",
    "#     result[N] = {'deep': {'recall': r_d, 'precision': p_d}}\n",
    "    \n",
    "    # HYBRID\n",
    "#     p_d, r_d = run(user_profiles_deep, N, HYBRID_FEATURES)\n",
    "#     p_d, r_d = run(user_profiles, N, HYBRID_FEATURES)\n",
    "#     print \"Hybrid Recall\", r_d, \"Hybrid Precision\", p_d, \"For iteration with\", N, \"\\n\\n\"\n",
    "#     result[N] = {'hybrid': {'recall': r_d, 'precision': p_d}}\n",
    "\n",
    "    p, r, mae = recommender_classifier.recommend_random(user_profiles, N)\n",
    "    print \"Random Recall\", r, \"Random Precision\",  p, \"Random MAE\", mae, \"For iteration with\", N\n",
    "    \n",
    "#     result = {'ll': {'recall': r_l, 'precision': p_l}, 'deep': {'recall': r_d, 'precision': p_d}, 'random': {'recall': r, 'precision': p}}\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-Level Recall 0.428271964732 Low-Level Precision 0.0428271964732 For iteration with 10 \n",
      "\n",
      "\n",
      "Deep Recall 0.474708711201 Deep Precision 0.0474708711201 For iteration with 10 \n",
      "\n",
      "\n",
      "Random Recall 0.0 Random Precision 0.0 Random MAE 1.31053255668 For iteration with 10\n",
      "User Avg Recall 0.0 User Avg Precision 0.0 User Avg MAE 1.31053255668 For iteration with 10\n",
      "541.164047003\n"
     ]
    }
   ],
   "source": [
    "q = Queue()\n",
    "N = 10\n",
    "start = time.time()\n",
    "# experiment(N, user_profiles, LOW_LEVEL_FEATURES, DEEP_FEATURES, HYBRID_FEATURES)\n",
    "# procs = [Process(target=experiment, args=(N, user_profiles, LOW_LEVEL_FEATURES, DEEP_FEATURES, HYBRID_FEATURES,)) for i in range(1)]\n",
    "# for p in procs: p.start()\n",
    "# for p in procs: p.join()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "#     p = Process(target=experiment, args=(q, N, user_profiles_low_level, LOW_LEVEL_FEATURES, user_profiles_deep, DEEP_FEATURES, Users,))\n",
    "#     p.start()\n",
    "#     N += 1\n",
    "# print q.get()\n",
    "# p.join()\n",
    "\n",
    "p = Pool(5)\n",
    "print(p.map(run, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
