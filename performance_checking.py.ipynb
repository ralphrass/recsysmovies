{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# necessary modules\n",
    "import sqlite3\n",
    "import utils\n",
    "import recommender_classifier\n",
    "import time\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "from multiprocessing import Process, Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load random users and feature vectors\n",
    "conn = sqlite3.connect('database.db')\n",
    "LOW_LEVEL_FEATURES, DEEP_FEATURES_RESNET, HYBRID_FEATURES_RESNET = utils.extract_features()\n",
    "foo, DEEP_FEATURES_BOF, HYBRID_FEATURES_BOF = utils.extract_features('bof_128.bin')\n",
    "# USER_TFIDF_FEATURES, MOVIE_TFIDF_FEATURES = utils.extract_tfidf_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Users = utils.selectRandomUsers(conn, 0.0001)\n",
    "print len(Users)\n",
    "user_profiles_small = recommender_classifier.build_user_profiles(conn, Users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Users = utils.selectRandomUsers(conn, 0.01)\n",
    "print len(Users)\n",
    "user_profiles_average = recommender_classifier.build_user_profiles(conn, Users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Users = utils.selectRandomUsers(conn, 0.1)\n",
    "print len(Users)\n",
    "user_profiles_big = recommender_classifier.build_user_profiles(conn, Users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Users = utils.selectRandomUsers(conn, 1)\n",
    "print len(Users)\n",
    "user_profiles_full = recommender_classifier.build_user_profiles(conn, Users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138445\n"
     ]
    }
   ],
   "source": [
    "Users = utils.selectRandomUsers(conn, None)\n",
    "print len(Users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13844\n"
     ]
    }
   ],
   "source": [
    "print len(Users)/10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tam = len(Users)/10\n",
    "part1 = Users[:tam]\n",
    "# part2 = Users[tam:tam*2]\n",
    "# part3 = Users[:len(Users)/10]\n",
    "# part4 = Users[:len(Users)/10]\n",
    "# part5 = Users[:len(Users)/10]\n",
    "# part6 = Users[:len(Users)/10]\n",
    "# part7 = Users[:len(Users)/10]\n",
    "# part8 = Users[:len(Users)/10]\n",
    "# part9 = Users[:len(Users)/10]\n",
    "# part10 = Users[:len(Users)/10]\n",
    "\n",
    "users_profiles_part = recommender_classifier.build_user_profiles(conn, part1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run(user_profiles, N, feature_vector, feature_vector2=None):\n",
    "\n",
    "    conn = sqlite3.connect('database.db')\n",
    "    \n",
    "    SumRecall, SumPrecision = 0, 0\n",
    "    \n",
    "    for user, profile in user_profiles.iteritems():                \n",
    "        \n",
    "        if feature_vector2 is not None:\n",
    "            if np.sum(feature_vector[user]) == 0:\n",
    "                print \"Blank user profile\", user\n",
    "                continue\n",
    "        \n",
    "        hits = 0\n",
    "        \n",
    "        predictions = recommender_classifier.get_predict_collaborative_filtering(conn, profile, feature_vector, feature_vector2)\n",
    "        # print \"Predictions\", sorted(predictions, key=lambda tup: tup[2], reverse=True)\n",
    "        \n",
    "        for elite_movie in profile['datasets']['elite_test']:\n",
    "                        \n",
    "            if feature_vector is list and elite_movie[0] not in feature_vector:\n",
    "                continue\n",
    "                \n",
    "            # Predict to the user movie and to random movies that the user did not rated\n",
    "            # print predictions            \n",
    "            elite_prediction = recommender_classifier.get_prediction_elite(conn, elite_movie, profile, feature_vector, feature_vector2)\n",
    "            all_predictions = predictions[:]\n",
    "            all_predictions.append(elite_prediction)\n",
    "            \n",
    "            # print \"Elite Movie\", elite_movie, elite_prediction\n",
    "            \n",
    "            hits += recommender_classifier.count_hit(all_predictions, elite_movie, N)\n",
    "        try:\n",
    "            recall = hits / float(len(profile['datasets']['elite_test']))\n",
    "            SumRecall += recall\n",
    "            SumPrecision += (recall / float(N))\n",
    "        except ZeroDivisionError:\n",
    "            continue\n",
    "        # print \"Size is\", len(predictions)\n",
    "        # print \"Predictions\", sorted(predictions, key=lambda tup: tup[2], reverse=True)\n",
    "\n",
    "    size = len(user_profiles)\n",
    "    avgRecall = utils.evaluateAverage(SumRecall, size)\n",
    "    avgPrecision = utils.evaluateAverage(SumPrecision, size)\n",
    "\n",
    "    return avgPrecision, avgRecall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import recommend_random\n",
    "\n",
    "# def experiment(N, user_profiles_low_level, LOW_LEVEL_FEATURES, user_profiles_deep, DEEP_FEATURES):\n",
    "def experiment(N, user_profiles, res_ll,res_random,res_deep_bof,res_hybrid_bof):\n",
    "    \n",
    "    global LOW_LEVEL_FEATURES, DEEP_FEATURES_BOF, HYBRID_FEATURES_BOF\n",
    "    \n",
    "    result = {}\n",
    "    start = time.time()\n",
    "    \n",
    "    # Tag-based\n",
    "    # p_t, r_t = run(user_profiles, N, USER_TFIDF_FEATURES, MOVIE_TFIDF_FEATURES)\n",
    "    # print \"Tag-based Recall\", r_t, \"Tag-based Precision\", p_t, \"For iteration with\", N\n",
    "    \n",
    "    # LOW LEVEL FEATURES check precision, recall and mae\n",
    "    p_l, r_l = run(user_profiles, N, LOW_LEVEL_FEATURES)\n",
    "    res_ll[N] = {'ll': {'recall': r_l, 'precision': p_l} }\n",
    "    print \"Low-Level Recall\", r_l, \"Low-Level Precision\", p_l, \"For iteration with\", N\n",
    "        \n",
    "    # DEEP FEATURES - BOF\n",
    "    p_d, r_d = run(user_profiles, N, DEEP_FEATURES_BOF)\n",
    "    res_deep_bof[N] = {'deep_bof': {'recall': r_d, 'precision': p_d} }\n",
    "    print \"Deep BOF Recall\", r_d, \"Deep BOF Precision\", p_d, \"For iteration with\", N        \n",
    "    \n",
    "    # HYBRID - BOF\n",
    "    p_h, r_h = run(user_profiles, N, HYBRID_FEATURES_BOF)\n",
    "    res_hybrid_bof[N] = {'hybrid_bof': {'recall': r_h, 'precision': p_h}}\n",
    "    print \"Hybrid BOF Recall\", r_h, \"Hybrid BOF Precision\", p_h, \"For iteration with\", N    \n",
    "\n",
    "    p, r, mae = recommender_classifier.recommend_random(user_profiles, N)\n",
    "    res_random[N] = {'random': {'recall': r, 'precision': p}}\n",
    "    print \"Random Recall\", r, \"Random Precision\",  p, \"Random MAE\", mae, \"For iteration with\", N\n",
    "    \n",
    "    # return_dict[N] = {'ll': {'recall': r_l, 'precision': p_l}, 'deep': {'recall': r_d, 'precision': p_d}, 'hybrid': {'recall': r_h, 'precision': p_h}, 'random': {'recall': r, 'precision': p}}    \n",
    "    end = time.time()\n",
    "    print \"Execution time\", (end - start)\n",
    "    \n",
    "#     result = {'ll': {'recall': r_l, 'precision': p_l}, 'deep': {'recall': r_d, 'precision': p_d}, 'random': {'recall': r, 'precision': p}}\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_profiles = users_profiles_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "res_ll = manager.dict()\n",
    "# res_deep = manager.dict()\n",
    "# res_hybrid = manager.dict()\n",
    "res_deep_bof = manager.dict()\n",
    "res_hybrid_bof = manager.dict()\n",
    "res_random = manager.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-5:\n",
      "KeyboardInterrupt\n",
      "Process Process-6:\n",
      "Process Process-4:\n",
      "Process Process-2:\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-8-5430396c0d7e>\", line 16, in experiment\n",
      "  File \"<ipython-input-8-5430396c0d7e>\", line 16, in experiment\n",
      "  File \"<ipython-input-8-5430396c0d7e>\", line 16, in experiment\n",
      "  File \"<ipython-input-8-5430396c0d7e>\", line 16, in experiment\n",
      "    p_l, r_l = run(user_profiles, N, LOW_LEVEL_FEATURES)\n",
      "    p_l, r_l = run(user_profiles, N, LOW_LEVEL_FEATURES)\n",
      "  File \"<ipython-input-8-5430396c0d7e>\", line 16, in experiment\n",
      "    p_l, r_l = run(user_profiles, N, LOW_LEVEL_FEATURES)\n",
      "    p_l, r_l = run(user_profiles, N, LOW_LEVEL_FEATURES)\n",
      "  File \"<ipython-input-7-574dc79c3623>\", line 16, in run\n",
      "  File \"<ipython-input-7-574dc79c3623>\", line 16, in run\n",
      "    p_l, r_l = run(user_profiles, N, LOW_LEVEL_FEATURES)\n",
      "  File \"<ipython-input-7-574dc79c3623>\", line 16, in run\n",
      "    predictions = recommender_classifier.get_predict_collaborative_filtering(conn, profile, feature_vector, feature_vector2)\n",
      "  File \"<ipython-input-7-574dc79c3623>\", line 26, in run\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0e5f6b8b673b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mproc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m# print return_dict.values()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/process.pyc\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0m_current_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/forking.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0mdeadline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mdelay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0005\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/forking.pyc\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    predictions = recommender_classifier.get_predict_collaborative_filtering(conn, profile, feature_vector, feature_vector2)\n",
      "    predictions = recommender_classifier.get_predict_collaborative_filtering(conn, profile, feature_vector, feature_vector2)\n",
      "    elite_prediction = recommender_classifier.get_prediction_elite(conn, elite_movie, profile, feature_vector, feature_vector2)\n",
      "  File \"recommender_classifier.py\", line 296, in get_prediction_elite\n",
      "    prediction = predictUserRating(conn, user_profile, elite_movie, feature_vector, feature_vector2)\n",
      "  File \"recommender_classifier.py\", line 265, in predictUserRating\n",
      "  File \"recommender_classifier.py\", line 315, in get_predict_collaborative_filtering\n",
      "  File \"recommender_classifier.py\", line 315, in get_predict_collaborative_filtering\n",
      "  File \"recommender_classifier.py\", line 315, in get_predict_collaborative_filtering\n",
      "    prediction = predictUserRating(conn, user_profile, random_movie, feature_vector, feature_vector2)\n",
      "    prediction = predictUserRating(conn, user_profile, random_movie, feature_vector, feature_vector2)\n",
      "    prediction = predictUserRating(conn, user_profile, random_movie, feature_vector, feature_vector2)\n",
      "  File \"recommender_classifier.py\", line 265, in predictUserRating\n",
      "  File \"recommender_classifier.py\", line 265, in predictUserRating\n",
      "  File \"recommender_classifier.py\", line 265, in predictUserRating\n",
      "  File \"<ipython-input-7-574dc79c3623>\", line 16, in run\n",
      "    predictions = recommender_classifier.get_predict_collaborative_filtering(conn, profile, feature_vector, feature_vector2)\n",
      "  File \"recommender_classifier.py\", line 315, in get_predict_collaborative_filtering\n",
      "    prediction = predictUserRating(conn, user_profile, random_movie, feature_vector, feature_vector2)\n",
      "  File \"recommender_classifier.py\", line 265, in predictUserRating\n",
      "    AllSimilarities = [(movieJ, cosine(movieI, movieJ, feature_vector)) for movieJ in all_movies]\n",
      "    AllSimilarities = [(movieJ, cosine(movieI, movieJ, feature_vector)) for movieJ in all_movies]\n",
      "    AllSimilarities = [(movieJ, cosine(movieI, movieJ, feature_vector)) for movieJ in all_movies]\n",
      "    AllSimilarities = [(movieJ, cosine(movieI, movieJ, feature_vector)) for movieJ in all_movies]\n",
      "    AllSimilarities = [(movieJ, cosine(movieI, movieJ, feature_vector)) for movieJ in all_movies]\n",
      "  File \"recommender_classifier.py\", line 64, in cosine\n",
      "  File \"recommender_classifier.py\", line 64, in cosine\n",
      "  File \"recommender_classifier.py\", line 64, in cosine\n",
      "  File \"recommender_classifier.py\", line 64, in cosine\n",
      "  File \"recommender_classifier.py\", line 64, in cosine\n",
      "    return cosine_similarity([featuresI], [featuresJ])\n",
      "    return cosine_similarity([featuresI], [featuresJ])\n",
      "    return cosine_similarity([featuresI], [featuresJ])\n",
      "    return cosine_similarity([featuresI], [featuresJ])\n",
      "    return cosine_similarity([featuresI], [featuresJ])\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/sklearn/metrics/pairwise.py\", line 911, in cosine_similarity\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/sklearn/metrics/pairwise.py\", line 907, in cosine_similarity\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/sklearn/metrics/pairwise.py\", line 911, in cosine_similarity\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/sklearn/metrics/pairwise.py\", line 905, in cosine_similarity\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/sklearn/metrics/pairwise.py\", line 911, in cosine_similarity\n",
      "    Y_normalized = normalize(Y, copy=True)\n",
      "    Y_normalized = normalize(Y, copy=True)\n",
      "    X, Y = check_pairwise_arrays(X, Y)\n",
      "    X_normalized = normalize(X, copy=True)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/sklearn/metrics/pairwise.py\", line 111, in check_pairwise_arrays\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py\", line 1344, in normalize\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py\", line 1362, in normalize\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py\", line 1362, in normalize\n",
      "    warn_on_dtype=warn_on_dtype, estimator=estimator)\n",
      "    Y_normalized = normalize(Y, copy=True)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py\", line 1344, in normalize\n",
      "    norms = row_norms(X)\n",
      "    norms = row_norms(X)\n",
      "    estimator='the normalize function', dtype=FLOAT_DTYPES)\n",
      "    estimator='the normalize function', dtype=FLOAT_DTYPES)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/sklearn/utils/extmath.py\", line 72, in row_norms\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/sklearn/utils/extmath.py\", line 72, in row_norms\n",
      "    norms = np.einsum('ij,ij->i', X, X)\n",
      "    norms = np.einsum('ij,ij->i', X, X)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py\", line 407, in check_array\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py\", line 409, in check_array\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py\", line 409, in check_array\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "    shape_repr = _shape_repr(array.shape)\n",
      "    _assert_all_finite(array)\n",
      "    shape_repr = _shape_repr(array.shape)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py\", line 159, in _shape_repr\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py\", line 159, in _shape_repr\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py\", line 55, in _assert_all_finite\n",
      "    joined = \", \".join(\"%d\" % e for e in shape)\n",
      "    joined = \", \".join(\"%d\" % e for e in shape)\n",
      "    if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py\", line 159, in <genexpr>\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.py\", line 32, in _sum\n",
      "    joined = \", \".join(\"%d\" % e for e in shape)\n",
      "KeyboardInterrupt\n",
      "    return umr_sum(a, axis, dtype, out, keepdims)\n"
     ]
    }
   ],
   "source": [
    "iterations = range(1, 6)\n",
    "\n",
    "jobs = []\n",
    "for num in iterations:\n",
    "    p = Process(target=experiment, args=(num,user_profiles, res_ll,res_random,res_deep_bof,res_hybrid_bof))\n",
    "    jobs.append(p)\n",
    "    p.start()\n",
    "\n",
    "for proc in jobs:\n",
    "    proc.join()\n",
    "# print return_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterations = range(6, 11)\n",
    "\n",
    "jobs = []\n",
    "for num in iterations:\n",
    "    p = Process(target=experiment, args=(num,user_profiles, res_ll,res_random,res_deep_bof,res_hybrid_bof))\n",
    "    jobs.append(p)\n",
    "    p.start()\n",
    "\n",
    "for proc in jobs:\n",
    "    proc.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "low_level_recall = [item['ll']['recall'] for item in res_ll.values()]\n",
    "# deep_recall = [item['deep_resnet']['recall'] for item in res_deep.values()]\n",
    "# hybrid_recall = [item['hybrid_resnet']['recall'] for item in res_hybrid.values()]\n",
    "deep_bof_recall = [item['deep_bof']['recall'] for item in res_deep_bof.values()]\n",
    "hybrid_bof_recall = [item['hybrid_bof']['recall'] for item in res_hybrid_bof.values()]\n",
    "random_recall = [item['random']['recall'] for item in res_random.values()]\n",
    "\n",
    "# print low_level_recall\n",
    "# print deep_recall\n",
    "# print low_level_recall\n",
    "\n",
    "# for key, value in res_ll.items():\n",
    "#      print \"Entry\", key, value\n",
    "\n",
    "with open('results_13844_users_6_to_10.txt', 'a') as resfile:\n",
    "    for key, value in res_ll.items():\n",
    "        resfile.write(str(key)+str(value)+\"\\n\")\n",
    "    for key, value in res_deep_bof.items():\n",
    "        resfile.write(str(key) + str(value)+\"\\n\")\n",
    "    for key, value in res_hybrid_bof.items():\n",
    "        resfile.write(str(key) + str(value)+\"\\n\")\n",
    "    for key, value in res_random.items():\n",
    "        resfile.write(str(key) + str(value)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(iterations, low_level_recall, 'r-', iterations, deep_recall, 'g-', iterations, hybrid_recall, 'b-', iterations, deep_bof_recall, 'c-', iterations, hybrid_bof_recall, 'k-', iterations, random_recall, 'y-')\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Iterations')\n",
    "plt.show()\n",
    "\n",
    "iterations = range(1, 6)\n",
    "plt.plot(iterations, low_level_recall, 'r-', iterations, deep_recall, 'g-', iterations, hybrid_recall, 'b-', iterations, deep_bof_recall, 'c-', iterations, hybrid_bof_recall, 'k-', iterations, random_recall, 'y-')\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Iterations')\n",
    "plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# # Be sure to only pick integer tick locations.\n",
    "# for axis in [ax.xaxis, ax.yaxis]:\n",
    "#     axis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "\n",
    "# # Plot anything (note the non-integer min-max values)...\n",
    "# x = np.linspace(-0.1, np.pi, 100)\n",
    "# ax.plot(range(1,6), low_level_recall, 'r--', range(1,6), deep_recall, 'g--', range(1,6), hybrid_recall, 'b--', range(1,6), random_recall, 'y--')\n",
    "\n",
    "# # Just for appearance's sake\n",
    "# ax.margins(0.05)\n",
    "# ax.axis('tight')\n",
    "# fig.tight_layout()\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
